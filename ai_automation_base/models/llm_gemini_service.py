from odoo import models, fields, api, _
from odoo.exceptions import ValidationError, UserError
import json
import logging
import requests
from typing import Dict, List, Optional, Any, Union

_logger = logging.getLogger(__name__)


class LLMGeminiService(models.Model):
    """Google Gemini LLM service implementation."""
    
    _name = 'llm.gemini.service'
    _description = 'Google Gemini LLM Service'
    _inherit = 'llm.base.service'
    
    def generate_text(self, prompt: str, model: str = None, **kwargs) -> str:
        """Generate text using Google Gemini's generateContent API."""
        if not model:
            model = self.get_default_model()
        
        # Validate parameters
        validated_params = self.validate_parameters(**kwargs)
        
        # Prepare request data for Gemini
        request_data = {
            'contents': [{
                'parts': [{
                    'text': prompt
                }]
            }],
            'generationConfig': {}
        }
        
        # Map parameters to Gemini format
        if 'temperature' in validated_params:
            request_data['generationConfig']['temperature'] = validated_params['temperature']
        if 'max_tokens' in validated_params:
            request_data['generationConfig']['maxOutputTokens'] = validated_params['max_tokens']
        if 'top_p' in validated_params:
            request_data['generationConfig']['topP'] = validated_params['top_p']
        if 'stop_sequences' in validated_params:
            request_data['generationConfig']['stopSequences'] = validated_params['stop_sequences']
        
        try:
            # Make API request
            api_key = self.get_api_key()
            url = f"{self.get_base_url()}/models/{model}:generateContent?key={api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            response = requests.post(
                url,
                headers=headers,
                json=request_data,
                timeout=30
            )
            
            # Handle rate limits
            self.handle_rate_limits(response)
            
            if response.status_code == 200:
                response_data = response.json()
                
                # Extract generated text from Gemini response
                if 'candidates' in response_data and response_data['candidates']:
                    candidate = response_data['candidates'][0]
                    if 'content' in candidate and candidate['content']['parts']:
                        generated_text = candidate['content']['parts'][0]['text'].strip()
                        
                        # Log successful request
                        self.log_request(request_data, response_data, 'success')
                        
                        return generated_text
                    else:
                        raise UserError(_('No content generated by Gemini'))
                else:
                    raise UserError(_('No candidates returned by Gemini'))
            else:
                error_data = response.json() if response.content else {}
                error_message = error_data.get('error', {}).get('message', f'HTTP {response.status_code}')
                
                # Log failed request
                self.log_request(request_data, error_data, 'error', error_message)
                
                raise UserError(_('Gemini API error: %s') % error_message)
                
        except requests.exceptions.RequestException as e:
            error_message = f"Network error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Network error: %s') % str(e))
        except Exception as e:
            error_message = f"Unexpected error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Unexpected error: %s') % str(e))
    
    def chat_completion(self, messages: List[Dict], model: str = None, **kwargs) -> Dict:
        """Generate chat completion using Google Gemini's chat API."""
        if not model:
            model = self.get_default_model()
        
        # Validate parameters
        validated_params = self.validate_parameters(**kwargs)
        
        # Convert messages to Gemini format
        contents = []
        for message in messages:
            role = message.get('role', 'user')
            content = message.get('content', '')
            
            # Map OpenAI roles to Gemini roles
            if role == 'system':
                # Gemini doesn't have system messages, prepend to first user message
                if contents and contents[0]['role'] == 'user':
                    contents[0]['parts'][0]['text'] = f"{content}\n\n{contents[0]['parts'][0]['text']}"
                else:
                    # If no user message yet, create one
                    contents.append({
                        'role': 'user',
                        'parts': [{'text': content}]
                    })
            else:
                contents.append({
                    'role': role,
                    'parts': [{'text': content}]
                })
        
        # Prepare request data
        request_data = {
            'contents': contents,
            'generationConfig': {}
        }
        
        # Map parameters to Gemini format
        if 'temperature' in validated_params:
            request_data['generationConfig']['temperature'] = validated_params['temperature']
        if 'max_tokens' in validated_params:
            request_data['generationConfig']['maxOutputTokens'] = validated_params['max_tokens']
        if 'top_p' in validated_params:
            request_data['generationConfig']['topP'] = validated_params['top_p']
        if 'stop_sequences' in validated_params:
            request_data['generationConfig']['stopSequences'] = validated_params['stop_sequences']
        
        try:
            # Make API request
            api_key = self.get_api_key()
            url = f"{self.get_base_url()}/models/{model}:generateContent?key={api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            response = requests.post(
                url,
                headers=headers,
                json=request_data,
                timeout=30
            )
            
            # Handle rate limits
            self.handle_rate_limits(response)
            
            if response.status_code == 200:
                response_data = response.json()
                
                # Log successful request
                self.log_request(request_data, response_data, 'success')
                
                return response_data
            else:
                error_data = response.json() if response.content else {}
                error_message = error_data.get('error', {}).get('message', f'HTTP {response.status_code}')
                
                # Log failed request
                self.log_request(request_data, error_data, 'error', error_message)
                
                raise UserError(_('Gemini API error: %s') % error_message)
                
        except requests.exceptions.RequestException as e:
            error_message = f"Network error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Network error: %s') % str(e))
        except Exception as e:
            error_message = f"Unexpected error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Unexpected error: %s') % str(e))
    
    def get_embeddings(self, text: str, model: str = None) -> List[float]:
        """Get embeddings using Google Gemini's embedding API."""
        if not model:
            model = 'embedding-001'  # Default Gemini embedding model
        
        request_data = {
            'model': f'models/{model}',
            'text': text,
        }
        
        try:
            # Make API request
            api_key = self.get_api_key()
            url = f"{self.get_base_url()}/models/{model}:embedText?key={api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            response = requests.post(
                url,
                headers=headers,
                json=request_data,
                timeout=30
            )
            
            # Handle rate limits
            self.handle_rate_limits(response)
            
            if response.status_code == 200:
                response_data = response.json()
                embeddings = response_data['embedding']['values']
                
                # Log successful request
                self.log_request(request_data, response_data, 'success')
                
                return embeddings
            else:
                error_data = response.json() if response.content else {}
                error_message = error_data.get('error', {}).get('message', f'HTTP {response.status_code}')
                
                # Log failed request
                self.log_request(request_data, error_data, 'error', error_message)
                
                raise UserError(_('Gemini API error: %s') % error_message)
                
        except requests.exceptions.RequestException as e:
            error_message = f"Network error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Network error: %s') % str(e))
        except Exception as e:
            error_message = f"Unexpected error: {str(e)}"
            self.log_request(request_data, {}, 'error', error_message)
            raise UserError(_('Unexpected error: %s') % str(e))
    
    def stream_response(self, prompt: str, model: str = None, **kwargs):
        """Stream response from Google Gemini."""
        if not model:
            model = self.get_default_model()
        
        # Validate parameters
        validated_params = self.validate_parameters(**kwargs)
        
        # Prepare request data for streaming
        request_data = {
            'contents': [{
                'parts': [{
                    'text': prompt
                }]
            }],
            'generationConfig': {}
        }
        
        # Map parameters to Gemini format
        if 'temperature' in validated_params:
            request_data['generationConfig']['temperature'] = validated_params['temperature']
        if 'max_tokens' in validated_params:
            request_data['generationConfig']['maxOutputTokens'] = validated_params['max_tokens']
        if 'top_p' in validated_params:
            request_data['generationConfig']['topP'] = validated_params['top_p']
        if 'stop_sequences' in validated_params:
            request_data['generationConfig']['stopSequences'] = validated_params['stop_sequences']
        
        try:
            # Make streaming API request
            api_key = self.get_api_key()
            url = f"{self.get_base_url()}/models/{model}:streamGenerateContent?key={api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            response = requests.post(
                url,
                headers=headers,
                json=request_data,
                timeout=30,
                stream=True
            )
            
            if response.status_code == 200:
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            data = line[6:]  # Remove 'data: ' prefix
                            if data == '[DONE]':
                                break
                            try:
                                chunk = json.loads(data)
                                if 'candidates' in chunk and chunk['candidates']:
                                    candidate = chunk['candidates'][0]
                                    if 'content' in candidate and candidate['content']['parts']:
                                        text = candidate['content']['parts'][0].get('text', '')
                                        if text:
                                            yield text
                            except json.JSONDecodeError:
                                continue
            else:
                error_data = response.json() if response.content else {}
                error_message = error_data.get('error', {}).get('message', f'HTTP {response.status_code}')
                raise UserError(_('Gemini API error: %s') % error_message)
                
        except requests.exceptions.RequestException as e:
            raise UserError(_('Network error: %s') % str(e))
        except Exception as e:
            raise UserError(_('Unexpected error: %s') % str(e))
    
    def call_function(self, function_name: str, arguments: Dict) -> Any:
        """Call a function using Gemini's function calling feature."""
        # This would be implemented with the function calling framework
        # For now, return a placeholder
        return f"Function {function_name} called with arguments: {arguments}"
    
    def get_available_functions(self) -> List[Dict]:
        """Get list of available functions for Gemini."""
        # This would return the registered function schemas
        return [] 